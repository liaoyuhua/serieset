{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from serieset import TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/ETTh1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process raw dataset: add group_id column (required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"group_id\"] = \"ETTh1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date   HUFL   HULL   MUFL   MULL   LUFL   LULL         OT  \\\n",
      "0  2016-07-01 00:00:00  5.827  2.009  1.599  0.462  4.203  1.340  30.531000   \n",
      "1  2016-07-01 01:00:00  5.693  2.076  1.492  0.426  4.142  1.371  27.787001   \n",
      "2  2016-07-01 02:00:00  5.157  1.741  1.279  0.355  3.777  1.218  27.787001   \n",
      "3  2016-07-01 03:00:00  5.090  1.942  1.279  0.391  3.807  1.279  25.044001   \n",
      "4  2016-07-01 04:00:00  5.358  1.942  1.492  0.462  3.868  1.279  21.948000   \n",
      "\n",
      "  group_id  \n",
      "0    ETTh1  \n",
      "1    ETTh1  \n",
      "2    ETTh1  \n",
      "3    ETTh1  \n",
      "4    ETTh1  \n",
      "minimum date: 2016-07-01 00:00:00\n",
      "maximum date: 2018-06-26 19:00:00\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print(f\"minimum date: {data['date'].min()}\")\n",
    "print(f\"maximum date: {data['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here is some arguments for TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'target_col': 'OT',\n",
    "    'features': [\"HUFL\", \"HULL\"],\n",
    "    'group_id': 'group_id',\n",
    "    'date_col': 'date',\n",
    "    'inp_len': 36,\n",
    "    'pred_len': 12,\n",
    "    'train_val_split_date': '2018-01-01 00:00:00',\n",
    "    'mode': 'train',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create TimeSeriesDataset instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset = TimeSeriesDataset(\n",
    "    data=data,\n",
    "    **params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimeSeriesDataset returns a dictionary of ['x', 'x_feats', 'y', 'group_id', 'sample_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of dataset is: dict_keys(['x', 'x_feats', 'y', 'group_id', 'sample_id'])\n"
     ]
    }
   ],
   "source": [
    "print(f\"output of dataset is: {torch_dataset[0].keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'x' is input time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x: torch.Size([36])\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of x: {torch_dataset[0]['x'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first sample not equal: 0\n"
     ]
    }
   ],
   "source": [
    "# check correctness\n",
    "not_equal = (torch_dataset[0]['x'].numpy() != data[\"OT\"][:params['inp_len']].astype(np.float32)).sum()\n",
    "print(f\"first sample not equal: {not_equal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'x_feats' is input covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_feats: torch.Size([36, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of x_feats: {torch_dataset[0]['x_feats'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first sample features not equal: HUFL    0\n",
      "HULL    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "not_equal = (torch_dataset[0]['x_feats'].numpy() != data[params['features']][:params['inp_len']].astype(np.float32)).sum()\n",
    "print(f\"first sample features not equal: {not_equal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'y' is target time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y: torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of y: {torch_dataset[0]['y'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first sample not equal: 0\n"
     ]
    }
   ],
   "source": [
    "# check correctness\n",
    "not_equal = (torch_dataset[0]['y'].numpy() != data[\"OT\"][params['inp_len']: params['inp_len']+ params['pred_len']].astype(np.float32)).sum()\n",
    "print(f\"first sample not equal: {not_equal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'group_id' is time series group id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group id: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"group id: {torch_dataset[0]['group_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### each training / validation sample has a 'sample_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample id: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"sample id: {torch_dataset[0]['sample_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### furthermore, you can check index manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_start</th>\n",
       "      <th>index_end</th>\n",
       "      <th>group_id</th>\n",
       "      <th>predict_start_date</th>\n",
       "      <th>sample_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-02 12:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-02 13:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-02 14:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-02 15:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-02 16:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13135</th>\n",
       "      <td>13135</td>\n",
       "      <td>13182</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-31 19:00:00</td>\n",
       "      <td>13135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13136</th>\n",
       "      <td>13136</td>\n",
       "      <td>13183</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-31 20:00:00</td>\n",
       "      <td>13136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13137</th>\n",
       "      <td>13137</td>\n",
       "      <td>13184</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-31 21:00:00</td>\n",
       "      <td>13137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13138</th>\n",
       "      <td>13138</td>\n",
       "      <td>13185</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-31 22:00:00</td>\n",
       "      <td>13138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13139</th>\n",
       "      <td>13139</td>\n",
       "      <td>13186</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-31 23:00:00</td>\n",
       "      <td>13139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13140 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index_start  index_end  group_id   predict_start_date  sample_id\n",
       "0                0         47         0  2016-07-02 12:00:00          0\n",
       "1                1         48         0  2016-07-02 13:00:00          1\n",
       "2                2         49         0  2016-07-02 14:00:00          2\n",
       "3                3         50         0  2016-07-02 15:00:00          3\n",
       "4                4         51         0  2016-07-02 16:00:00          4\n",
       "...            ...        ...       ...                  ...        ...\n",
       "13135        13135      13182         0  2017-12-31 19:00:00      13135\n",
       "13136        13136      13183         0  2017-12-31 20:00:00      13136\n",
       "13137        13137      13184         0  2017-12-31 21:00:00      13137\n",
       "13138        13138      13185         0  2017-12-31 22:00:00      13138\n",
       "13139        13139      13186         0  2017-12-31 23:00:00      13139\n",
       "\n",
       "[13140 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dataset.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group_time_series_dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
